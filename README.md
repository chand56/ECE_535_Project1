# ECE_535_Project1
# Security Analysis of Gaze Estimation in Mixed Reality

## Motivation
Head-mounted mixed-reality devices can render and overlay realistic 3D content onto the physical environment, enabling a wealth of interactive possibilities. These technologies are also used to track human pose. Gaze estimation models are important to track human gaze and improve the performance by overlaying virtual content precisely w.r.t physical world. These devices are equipped with a rich set of sensors that collect personal and sensitive information (e.g., body motion, eye gaze, hand joints, and facial expression), which is used to train gaze estimation models. Unfortunately most pre-trained models can be injected with backdoors that compromise the accuracy of these models and integrity of the entire system

## Design Goals and Deliverables

• Find Gaze Estimation Data sets and Models

• Find Gaze Estimation Backdoors and remove them

• Perform security analysis on the data based on existing literature

## System Blocks

TBT

## Hardware/Software Requirements

Python, Unity

## Team Member Responsibilities

Chandler Cheron - Backdoor Removal 
Tre Allen-Robinson - Research, literature analysis, software setup 
Aaron - Security analysis

## Project Timeline

Week 1-2: Research 
Week 3-4: Setup software and Backdoor removal 
Week 5-6: Security Analysis  
Week 7-8: Writing Paper

## References

SecureGaze: Defending Gaze Estimation Against Backdoor Attacks, SenSys 2025
See https://github.com/hysts/pytorch_mpiigaze

